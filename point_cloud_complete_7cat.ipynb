{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "point_cloud_complete_7cat.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcX5Wzy5rPkf",
        "colab_type": "code",
        "outputId": "659c237e-ec8c-482f-cd43-4bc64ef816ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "source": [
        "# Check GPU for Google Colab\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7410 sha256=ad847b1eb89535d837ad01429d61d3d8e75c27997d6d596071e0783167a93883\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-a3d887c1ae58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGPUtil\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mGPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mGPUs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetGPUs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mgpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPUs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprintm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpsutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGxqA9-2WM_B",
        "colab_type": "code",
        "outputId": "21e23e11-ce58-40fe-a930-5ea762657d78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB1CAvmTKuBT",
        "colab_type": "text"
      },
      "source": [
        "## This version uses shared weights layers.\n",
        "## It uses created triplet loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYyZZNm3aM0o",
        "colab_type": "code",
        "outputId": "53f2999d-4bf5-4b6d-d871-fd05f5c6fcaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from keras import optimizers\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Flatten, Reshape, Dropout, Add, merge, Subtract\n",
        "from keras.layers import Convolution1D, MaxPooling1D, BatchNormalization\n",
        "from keras.layers import concatenate, Lambda, Activation\n",
        "from keras import backend as K\n",
        "from keras.utils import np_utils\n",
        "import h5py\n",
        "import time\n",
        "import keras.layers\n",
        "from keras.engine.topology import Layer\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from scipy.spatial import distance\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style(\"darkgrid\")\n",
        "from mpl_toolkits.mplot3d import Axes3D"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NPxJXkfYxUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "category = \"building\"\n",
        "\n",
        "# number of points in each sample\n",
        "num_points = 2048"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlR5NyJOnmuC",
        "colab_type": "text"
      },
      "source": [
        "## **This version uses different poitnet**\n",
        "It works, but does not learn.\n",
        "Using different triplet loss.\n",
        "https://github.com/TianzhongSong/PointNet-Keras/blob/master/model_cls.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5QQAwEZV4E0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mat_mul(A, B):\n",
        "    return tf.matmul(A, B)\n",
        "\n",
        "\n",
        "def load_h5(h5_filename):\n",
        "    f = h5py.File(h5_filename)\n",
        "    data = f['data'][:]\n",
        "    label = f['label'][:]\n",
        "    id = f['id'][:]\n",
        "    return (data, label, id)\n",
        "\n",
        "\n",
        "def rotate_point_cloud(batch_data):\n",
        "    \"\"\" Randomly rotate the point clouds to augument the dataset\n",
        "        rotation is per shape based along up direction\n",
        "        Input:\n",
        "          BxNx3 array, original batch of point clouds\n",
        "        Return:\n",
        "          BxNx3 array, rotated batch of point clouds\n",
        "    \"\"\"\n",
        "    rotated_data = np.zeros(batch_data.shape, dtype=np.float32)\n",
        "    for k in range(batch_data.shape[0]):\n",
        "        rotation_angle = np.random.uniform() * 2 * np.pi\n",
        "        cosval = np.cos(rotation_angle)\n",
        "        sinval = np.sin(rotation_angle)\n",
        "        rotation_matrix = np.array([[cosval, 0, sinval],\n",
        "                                    [0, 1, 0],\n",
        "                                    [-sinval, 0, cosval]])\n",
        "        shape_pc = batch_data[k, ...]\n",
        "        rotated_data[k, ...] = np.dot(shape_pc.reshape((-1, 3)), rotation_matrix)\n",
        "    return rotated_data\n",
        "\n",
        "\n",
        "def jitter_point_cloud(batch_data, sigma=0.01, clip=0.05):\n",
        "    \"\"\" Randomly jitter points. jittering is per point.\n",
        "        Input:\n",
        "          BxNx3 array, original batch of point clouds\n",
        "        Return:\n",
        "          BxNx3 array, jittered batch of point clouds\n",
        "    \"\"\"\n",
        "    B, N, C = batch_data.shape\n",
        "    assert(clip > 0)\n",
        "    jittered_data = np.clip(sigma * np.random.randn(B, N, C), -1 * clip, clip)\n",
        "    jittered_data += batch_data\n",
        "    return jittered_data\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class MatMul(Layer):\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(MatMul, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Used purely for shape validation.\n",
        "        if not isinstance(input_shape, list):\n",
        "            raise ValueError('`MatMul` layer should be called '\n",
        "                             'on a list of inputs')\n",
        "        if len(input_shape) != 2:\n",
        "            raise ValueError('The input of `MatMul` layer should be a list containing 2 elements')\n",
        "\n",
        "        if len(input_shape[0]) != 3 or len(input_shape[1]) != 3:\n",
        "            raise ValueError('The dimensions of each element of inputs should be 3')\n",
        "\n",
        "        if input_shape[0][-1] != input_shape[1][1]:\n",
        "            raise ValueError('The last dimension of inputs[0] should match the dimension 1 of inputs[1]')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        if not isinstance(inputs, list):\n",
        "            raise ValueError('A `MatMul` layer should be called '\n",
        "                             'on a list of inputs.')\n",
        "        return tf.matmul(inputs[0], inputs[1])\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        output_shape = [input_shape[0][0], input_shape[0][1], input_shape[1][-1]]\n",
        "        return tuple(output_shape)\n",
        "\n",
        "\n",
        "def create_base_model():\n",
        "    input_points = Input(shape=(num_points, 3))\n",
        "    # issues\n",
        "    # input transformation net\n",
        "    x = Convolution1D(64, 1, activation='relu')(input_points)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Convolution1D(128, 1, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Convolution1D(1024, 1, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling1D(pool_size=num_points)(x)\n",
        "\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Dense(9, weights=[np.zeros([256, 9]), np.array([1, 0, 0, 0, 1, 0, 0, 0, 1]).astype(np.float32)])(x)\n",
        "    input_T = Reshape((3, 3))(x)\n",
        "\n",
        "    # forward net\n",
        "    g = MatMul()([input_points, input_T])\n",
        "    g = Convolution1D(64, 1, activation='relu')(g)\n",
        "    g = BatchNormalization()(g)\n",
        "    g = Convolution1D(64, 1, activation='relu')(g)\n",
        "    g = BatchNormalization()(g)\n",
        "\n",
        "    # feature transform net\n",
        "    f = Convolution1D(64, 1, activation='relu')(g)\n",
        "    f = BatchNormalization()(f)\n",
        "    f = Convolution1D(128, 1, activation='relu')(f)\n",
        "    f = BatchNormalization()(f)\n",
        "    f = Convolution1D(1024, 1, activation='relu')(f)\n",
        "    f = BatchNormalization()(f)\n",
        "    f = MaxPooling1D(pool_size=num_points)(f)\n",
        "    f = Dense(512, activation='relu')(f)\n",
        "    f = BatchNormalization()(f)\n",
        "    f = Dense(256, activation='relu')(f)\n",
        "    f = BatchNormalization()(f)\n",
        "    f = Dense(64 * 64, weights=[np.zeros([256, 64 * 64]), np.eye(64).flatten().astype(np.float32)])(f)\n",
        "    feature_T = Reshape((64, 64))(f)\n",
        "\n",
        "    # forward net\n",
        "    g = MatMul()([g, feature_T])\n",
        "    g = Convolution1D(64, 1, activation='relu')(g)\n",
        "    g = BatchNormalization()(g)\n",
        "    g = Convolution1D(128, 1, activation='relu')(g)\n",
        "    g = BatchNormalization()(g)\n",
        "    g = Convolution1D(1024, 1, activation='relu')(g)\n",
        "    g = BatchNormalization()(g)\n",
        "\n",
        "    # global feature\n",
        "    global_feature = MaxPooling1D(pool_size=num_points)(g)\n",
        "#     global_feature = Activation('sigmoid')(global_feature)\n",
        "    out = Flatten(name='out')(global_feature)\n",
        "    \n",
        "    model = Model(inputs=input_points, outputs=out)\n",
        "#     print(model.summary())\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VhHEObFyz5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ## Using pretrained model\n",
        "\n",
        "# def create_base_model():\n",
        "#   input_points = Input(shape=(num_points, 3))\n",
        "#   # input transformation net\n",
        "#   x = Convolution1D(64, 1, activation='relu')(input_points)\n",
        "#   x = BatchNormalization()(x)\n",
        "#   x = Convolution1D(128, 1, activation='relu')(x)\n",
        "#   x = BatchNormalization()(x)\n",
        "#   x = Convolution1D(1024, 1, activation='relu')(x)\n",
        "#   x = BatchNormalization()(x)\n",
        "#   x = MaxPooling1D(pool_size=num_points)(x)\n",
        "\n",
        "#   x = Dense(512, activation='relu')(x)\n",
        "#   x = BatchNormalization()(x)\n",
        "#   x = Dense(256, activation='relu')(x)\n",
        "#   x = BatchNormalization()(x)\n",
        "\n",
        "#   x = Dense(9, weights=[np.zeros([256, 9]), np.array([1, 0, 0, 0, 1, 0, 0, 0, 1]).astype(np.float32)])(x)\n",
        "#   input_T = Reshape((3, 3))(x)\n",
        "\n",
        "#   # forward net\n",
        "#   g = MatMul()([input_points, input_T])\n",
        "#   g = Convolution1D(64, 1, activation='relu')(g)\n",
        "#   g = BatchNormalization()(g)\n",
        "#   g = Convolution1D(64, 1, activation='relu')(g)\n",
        "#   g = BatchNormalization()(g)\n",
        "\n",
        "#   # feature transform net\n",
        "#   f = Convolution1D(64, 1, activation='relu')(g)\n",
        "#   f = BatchNormalization()(f)\n",
        "#   f = Convolution1D(128, 1, activation='relu')(f)\n",
        "#   f = BatchNormalization()(f)\n",
        "#   f = Convolution1D(1024, 1, activation='relu')(f)\n",
        "#   f = BatchNormalization()(f)\n",
        "#   f = MaxPooling1D(pool_size=num_points)(f)\n",
        "#   f = Dense(512, activation='relu')(f)\n",
        "#   f = BatchNormalization()(f)\n",
        "#   f = Dense(256, activation='relu')(f)\n",
        "#   f = BatchNormalization()(f)\n",
        "#   f = Dense(64 * 64, weights=[np.zeros([256, 64 * 64]), np.eye(64).flatten().astype(np.float32)])(f)\n",
        "#   feature_T = Reshape((64, 64))(f)\n",
        "\n",
        "#   # forward net\n",
        "#   g = MatMul()([g, feature_T])\n",
        "#   g = Convolution1D(64, 1, activation='relu')(g)\n",
        "#   g = BatchNormalization()(g)\n",
        "#   g = Convolution1D(128, 1, activation='relu')(g)\n",
        "#   g = BatchNormalization()(g)\n",
        "#   g = Convolution1D(1024, 1, activation='relu')(g)\n",
        "#   g = BatchNormalization()(g)\n",
        "\n",
        "#   # global feature\n",
        "#   global_feature = MaxPooling1D(pool_size=num_points)(g)\n",
        "#   #     global_feature = Activation('sigmoid')(global_feature)\n",
        "#   # out = Flatten()(global_feature)\n",
        "\n",
        "#   # point_net_cls\n",
        "#   c = Dense(512, activation='relu')(global_feature)\n",
        "#   c = BatchNormalization()(c)\n",
        "#   c = Dropout(0.5)(c)\n",
        "#   c = Dense(256, activation='relu')(c)\n",
        "#   c = BatchNormalization()(c)\n",
        "#   c = Dropout(0.5)(c)\n",
        "#   c = Dense(3, activation='softmax')(c)\n",
        "#   prediction = Flatten()(c)\n",
        "\n",
        "#   pre_model = Model(inputs=input_points, outputs=prediction)\n",
        "#   pre_model.load_weights('drive/My Drive/Weights/model_pretrain.h5')\n",
        "  \n",
        "#   ## Visualize network\n",
        "#   from keras.utils.vis_utils import plot_model as plot\n",
        "#   plot(pre_model, to_file = 'drive/My Drive/Triplet_Network_o.png')\n",
        "    \n",
        "#   out =  Flatten()(pre_model.get_layer(\"max_pooling1d_3\").output)\n",
        "#   model = Model(inputs=pre_model.input, outputs=out)\n",
        "\n",
        "#   return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4LcP2yBTCGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def triplet_loss(y_true, y_pred, alpha = 0.2, beta = 0.1):\n",
        "    \"\"\"\n",
        "    Implementation of the triplet loss function\n",
        "    Arguments:\n",
        "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
        "    y_pred -- python list containing three objects:\n",
        "            anchor -- the encodings for the anchor data\n",
        "            positive -- the encodings for the positive data (similar to anchor)\n",
        "            negative -- the encodings for the negative data (different from anchor)\n",
        "    Returns:\n",
        "    loss -- real number, value of the loss\n",
        "    \"\"\"\n",
        "    \n",
        "#     total_length = y_pred.shape.as_list()[-1]\n",
        "    total_length = 1024*3\n",
        "    \n",
        "    anchor = y_pred[:,0:int(total_length*1/3)]\n",
        "    positive = y_pred[:,int(total_length*1/3):int(total_length*2/3)]\n",
        "    negative = y_pred[:,int(total_length*2/3):int(total_length*3/3)]\n",
        "\n",
        "     # distance between the anchor and the positive\n",
        "    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n",
        "\n",
        "    # distance between the anchor and the negative\n",
        "    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n",
        "\n",
        "    # compute loss\n",
        "    basic_loss_a = pos_dist-neg_dist+alpha\n",
        "    loss_a = K.maximum(basic_loss_a,0.0)\n",
        "    \n",
        "    basic_loss_b = pos_dist - beta\n",
        "    loss_b = K.maximum(basic_loss_b,0.0)\n",
        "    \n",
        "    loss = loss_a + loss_b\n",
        "    \n",
        "    return loss_a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHcrflENTGXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compile_model(): \n",
        "  print(\"Compiling model...\")\n",
        "  input_anchor = Input(shape=(num_points, 3))\n",
        "  input_positive = Input(shape=(num_points, 3))\n",
        "  input_negative = Input(shape=(num_points, 3))\n",
        "\n",
        "  model_shared = create_base_model()\n",
        "\n",
        "  encoded_anchor = model_shared(input_anchor)\n",
        "  encoded_positive = model_shared(input_positive)\n",
        "  encoded_negative = model_shared(input_negative)\n",
        "\n",
        "#   optim = optimizers.Adam(lr=0.000001)\n",
        "  optim = optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=0.000001, decay=0.0)\n",
        "  # optim = optimizers.RMSprop(lr=0.00001)\n",
        "\n",
        "  merged_vector = concatenate([encoded_anchor, encoded_positive, encoded_negative], axis=1, name='merged_layer')\n",
        "\n",
        "  model = Model(inputs=[input_anchor, input_positive, input_negative], outputs=merged_vector)\n",
        "  model.compile(loss=triplet_loss, optimizer=optim)\n",
        "\n",
        "  ## Visualize network\n",
        "#   from keras.utils.vis_utils import plot_model as plot\n",
        "#   plot(model, to_file = 'drive/My Drive/Triplet_Network_o.png')\n",
        "\n",
        "\n",
        "#   model.summary()\n",
        "\n",
        "  return model\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wt-ETJY1Yj_V",
        "colab_type": "text"
      },
      "source": [
        "# Display point cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkqO5hfAUU34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "def show_pc(points):\n",
        "  # select one test data to visualize\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_subplot(111, projection='3d')\n",
        "  v_points = points\n",
        "  v_points = np.squeeze(v_points)\n",
        "\n",
        "  for i in range(v_points.shape[0]):\n",
        "      xs = v_points[i,0]\n",
        "      ys = v_points[i,1]\n",
        "      zs = v_points[i,2]\n",
        "      ax.scatter(xs, ys, zs, color=\"blue\", s=5)\n",
        "\n",
        "  ax.set_xlabel('X Label')\n",
        "  ax.set_ylabel('Y Label')\n",
        "  ax.set_zlabel('Z Label')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiksHuhBcIux",
        "colab_type": "text"
      },
      "source": [
        "## Train on Style Data 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtwnCkGnpVvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_triplet(mode=\"train\"):\n",
        "  # Evaluate on test data\n",
        "  if mode == \"train\":\n",
        "    X_test = [Anchor_train, Positive_train, Negative_train]\n",
        "    Y_dummy = np.zeros((Anchor_train.shape[0],1))\n",
        "  elif mode == \"test\":\n",
        "    X_test = [Anchor_test, Positive_test, Negative_test]\n",
        "    Y_dummy = np.zeros((Anchor_test.shape[0],1))\n",
        "  \n",
        "  pred = model.predict(x=X_test, verbose=1)\n",
        "  \n",
        "  # Split into anchor, a, and b sets\n",
        "  total_lenght = pred.shape[1]\n",
        "  pred_anchor = pred[:,0:int(total_lenght*1/3)]\n",
        "  pred_a = pred[:,int(total_lenght*1/3):int(total_lenght*2/3)]\n",
        "  pred_b = pred[:,int(total_lenght*2/3):int(total_lenght*3/3)]\n",
        "  pred_a.shape\n",
        "  \n",
        "#   print(pred_anchor)\n",
        "\n",
        "  result = []\n",
        "  for i in range(pred.shape[0]):\n",
        "    dist1 = distance.euclidean(pred_anchor[i], pred_a[i])\n",
        "    dist2 = distance.euclidean(pred_anchor[i], pred_b[i])\n",
        "#     print(pred_anchor[0])\n",
        "#     print(pred_a[0])\n",
        "#     print(pred_b[0])\n",
        "#     print(\"Positive dist: \", dist1)\n",
        "#     print(\"Negative dist: \", dist2)\n",
        "    if dist1 < dist2:\n",
        "      result.append(0)\n",
        "    else:\n",
        "      result.append(1)   \n",
        "\n",
        "  print(\"Evaluation accuracy: \", accuracy_score(Y_dummy, result))\n",
        "\n",
        "  return accuracy_score(Y_dummy, result)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfGdVJQg9bWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_3d(img_id=1):\n",
        "  total_length = 1500\n",
        "  \n",
        "  print(\"Plotting...\")\n",
        "  # Evaluate on test data\n",
        "  X = [input_data_anchor_test,input_data_a_test, input_data_b_test]\n",
        "  y_pred = model.predict(x=X,verbose=1)\n",
        "  \n",
        "  anchor = y_pred[:,0:int(total_length*1/3)]\n",
        "  positive = y_pred[:,int(total_length*1/3):int(total_length*2/3)]\n",
        "  negative = y_pred[:,int(total_length*2/3):int(total_length*3/3)]\n",
        "\n",
        "  data_plot = np.concatenate([anchor,positive,negative])\n",
        "\n",
        "  \n",
        "  pca = PCA(n_components=3)\n",
        "  pca.fit(data_plot)\n",
        "\n",
        "  data_plot = pca.transform(data_plot)\n",
        "\n",
        "  # Set colors\n",
        "  colors = []\n",
        "  num_data = 1\n",
        "  for i in range(0,num_data):\n",
        "    colors.append(\"red\")\n",
        "  for i in range(0,num_data):\n",
        "    colors.append(\"blue\")\n",
        "  for i in range(0,num_data):\n",
        "    colors.append(\"green\")\n",
        "\n",
        "  fig = plt.figure()\n",
        "  ax = Axes3D(fig)\n",
        "\n",
        "  ax.set_xlabel(\"X\")\n",
        "  ax.set_ylabel(\"Y\")\n",
        "  ax.set_zlabel(\"Z\")\n",
        "\n",
        "  ax.scatter(data_plot[:,0], data_plot[:,1], data_plot[:,2], marker=\"o\", color=colors, linestyle='None')\n",
        "  \n",
        "  img_name = \"drive/My Drive/Saved_Images/figure\" + str(img_id) + \".png\"\n",
        "  plt.savefig(img_name) \n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seFGLgPqlzLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_plot(eval_name, fold_id):\n",
        "  fig = plt.figure()\n",
        "\n",
        "  # top\n",
        "  ax1 = fig.add_subplot(2, 1, 1)\n",
        "  ax1.plot(df_history[0])\n",
        "  ax1.plot(df_history[1])\n",
        "  ax1.set_xlabel(\"epoch\")\n",
        "  ax1.set_ylabel(\"loss\")\n",
        "  plt.legend(['train_loss', 'val_loss'], loc='upper right', fontsize='x-small')\n",
        "  plt.title(\"Fold-\"+str(fold_id))\n",
        "\n",
        "  # bottom\n",
        "  ax2 = fig.add_subplot(2, 1, 2)\n",
        "  ax2.plot(df_history[2])\n",
        "  ax2.set_xlabel(\"epoch\")\n",
        "  ax2.set_ylabel(\"accuracy\")\n",
        "  plt.legend(['val_accuracy'], loc='upper left', fontsize='x-small')\n",
        "\n",
        "#   fig.show()\n",
        "  fig.savefig(\"drive/My Drive/Saved_Images/CV_eval_pc/\" + eval_name + \"/Fold-\"+str(fold_id))\n",
        "  plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f59DS2_EYSD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Create two plots; accuracy and loss\n",
        "def save_plot(eval_name, fold_id):\n",
        "  fig = plt.figure()\n",
        "\n",
        "  # top\n",
        "  ax1 = fig.add_subplot(2, 1, 1)\n",
        "  ax1.plot(df_history['train_loss'], color='blue')\n",
        "  ax1.plot(df_history['val_loss'], color='darkorange')\n",
        "  ax1.set_xlabel(\"epoch\")\n",
        "  ax1.set_ylabel(\"loss\")\n",
        "  plt.legend(['train_loss', 'val_loss'], loc='upper right', fontsize='x-small')\n",
        "  plt.title(\"Fold-\"+str(fold_id))\n",
        "\n",
        "  # bottom\n",
        "  ax2 = fig.add_subplot(2, 1, 2)\n",
        "  ax2.plot(df_history['val_acc'], color='orange')\n",
        "  ax2.set_xlabel(\"epoch\")\n",
        "  ax2.set_ylabel(\"accuracy\")\n",
        "  plt.legend(['val_accuracy'], loc='upper left', fontsize='x-small')\n",
        "\n",
        "#   fig.show()\n",
        "  fig.savefig(\"drive/My Drive/Saved_Images/CV_eval_pc/\" + eval_name + \"/Fold-\"+str(fold_id))\n",
        "  plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hL6bOfHcWh1T",
        "colab_type": "code",
        "outputId": "241292da-eb7b-475d-a6cb-0fb46b81ee7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Load point cloud\n",
        "num_points = 2048\n",
        "# Load point cloud data\n",
        "train_path = \"drive/My Drive/style_data_2/\"\n",
        "\n",
        "filenames = [d for d in os.listdir(train_path)]\n",
        "print(train_path)\n",
        "print(filenames)\n",
        "train_points = None\n",
        "train_labels = None\n",
        "train_ids = None\n",
        "for d in filenames:\n",
        "    cur_points, cur_labels, cur_ids = load_h5(os.path.join(train_path, d))\n",
        "    cur_points = cur_points.reshape(1, -1, 3)\n",
        "    cur_labels = cur_labels.reshape(1, -1)\n",
        "    cur_ids = cur_ids.reshape(1, -1)\n",
        "    if train_labels is None or train_points is None:\n",
        "        train_labels = cur_labels\n",
        "        train_points = cur_points\n",
        "        train_ids = cur_ids\n",
        "    else:\n",
        "        train_labels = np.hstack((train_labels, cur_labels))\n",
        "        train_points = np.hstack((train_points, cur_points))\n",
        "        train_ids = np.hstack((train_ids, cur_ids))\n",
        "train_points_r = train_points.reshape(-1, num_points, 3)\n",
        "train_labels_r = train_labels.reshape(-1, 1)\n",
        "train_ids_r = train_ids.reshape(-1, 1)\n",
        "\n",
        "\n",
        "\n",
        "def data_generator(fold_id):  \n",
        "  ## Generate training/test data\n",
        "  df_train = pd.read_pickle(\"drive/My Drive/10CV_df/Lun_building/df_train_\" + str(fold_id) + \".csv\")\n",
        "  df_test = pd.read_pickle(\"drive/My Drive/10CV_df/Lun_building/df_test_\" + str(fold_id) + \".csv\")\n",
        "\n",
        "  df_train = df_train.reset_index(drop=True)\n",
        "  df_test = df_test.reset_index(drop=True)\n",
        "\n",
        "  out_list = []\n",
        "  ################ Generate Training Data ################\n",
        "  name_list = [\"query\", \"pos\", \"neg\"]\n",
        "  data_length = len(df_train)\n",
        "\n",
        "  for k in range(0,3):\n",
        "    print(\"Generating training data\", k+1, \"/3...\")\n",
        "    input_data = pd.DataFrame()\n",
        "    df_ids = pd.DataFrame(train_ids_r)\n",
        "    for i in range(data_length):\n",
        "        data_id = df_train.loc[:,name_list[k]][i]\n",
        "        id_index = df_ids[df_ids[0].astype(str)== (\"b'\"+data_id + \".off'\")].index\n",
        "        input_data = input_data.append(pd.DataFrame(train_points_r[id_index[0]][:,[0,2,1]]))\n",
        "        \n",
        "    input_data = input_data.as_matrix()\n",
        "    input_data = input_data.reshape(-1, num_points, 3)\n",
        "    out_list.append(np.array(input_data))\n",
        "\n",
        "\n",
        "  ############### Generate Test Data #########################\n",
        "  data_length = len(df_test)\n",
        "\n",
        "  for k in range(0,3):\n",
        "    print(\"Generating training data\", k+1, \"/3...\")\n",
        "    input_data = pd.DataFrame()\n",
        "    df_ids = pd.DataFrame(train_ids_r)\n",
        "    for i in range(data_length):\n",
        "        data_id = df_test.loc[:,name_list[k]][i]\n",
        "        id_index = df_ids[df_ids[0].astype(str)== (\"b'\"+data_id + \".off'\")].index\n",
        "        input_data = input_data.append(pd.DataFrame(train_points_r[id_index[0]][:,[0,2,1]]))\n",
        "\n",
        "    input_data = input_data.as_matrix()\n",
        "    input_data = input_data.reshape(-1, num_points, 3)\n",
        "    out_list.append(np.array(input_data))\n",
        "    \n",
        "  return out_list\n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive/My Drive/style_data_2/\n",
            "['train_style_model_2.h5']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLIFNROVbm8M",
        "colab_type": "code",
        "outputId": "04a548ad-dc9e-4640-89b8-e52a1b748612",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "##### 10-fold cross-validation ###########\n",
        "for k in range(1,11):\n",
        "  \n",
        "  print(\"==================== Fold:\", k, \"/10 ========================\")\n",
        "  ####### Use for style data 1 #######\n",
        "  # Training and testing data\n",
        "  generated_data = data_generator(1)\n",
        "  model = compile_model()\n",
        "\n",
        "  Anchor_train = generated_data[0]\n",
        "  Positive_train = generated_data[1]\n",
        "  Negative_train = generated_data[2]\n",
        "\n",
        "  Anchor_test = generated_data[3]\n",
        "  Positive_test = generated_data[4]\n",
        "  Negative_test = generated_data[5]\n",
        "\n",
        "  Y_dummy1 = np.zeros((Anchor_train.shape[0],1))\n",
        "  Y_dummy2 = np.zeros((Anchor_test.shape[0],1))\n",
        "\n",
        "\n",
        "  # Time\n",
        "  start = time.time()\n",
        "\n",
        "  num_epoch = 500\n",
        "  # Fit model on training data\n",
        "  df_history = pd.DataFrame(columns=['train_loss','val_loss','train_acc','val_acc'])\n",
        "  for i in range(1, num_epoch):\n",
        "    print(\"\\n Total epoch:\", i, \"/\", num_epoch)\n",
        "\n",
        "    # rotate and jitter the points\n",
        "    train_points_rotate = rotate_point_cloud(Anchor_train)\n",
        "    train_points_jitter = jitter_point_cloud(train_points_rotate)\n",
        "    Anchor_train = jitter_point_cloud(Anchor_train)\n",
        "    train_points_rotate = rotate_point_cloud(Positive_train)\n",
        "    train_points_jitter = jitter_point_cloud(train_points_rotate)\n",
        "    Positive_train = jitter_point_cloud(Positive_train)\n",
        "    train_points_rotate = rotate_point_cloud(Negative_train)\n",
        "    train_points_jitter = jitter_point_cloud(train_points_rotate)\n",
        "    Negative_train = jitter_point_cloud(Negative_train) # !!!!!!!!!! changed !!!!!!!!!!!\n",
        "\n",
        "\n",
        "    # Evaluation\n",
        "    val_acc = evaluate_triplet(\"test\")\n",
        "    train_acc = evaluate_triplet(\"train\")\n",
        "\n",
        "    history = model.fit(x=[Anchor_train, Positive_train, Negative_train], y=Y_dummy1,\\\n",
        "                           validation_data=([Anchor_test,Positive_test,Negative_test],Y_dummy2),\\\n",
        "                           batch_size=16, shuffle=True, epochs=1,verbose=1)\n",
        "\n",
        "\n",
        "    df_history = df_history.append(pd.DataFrame([history.history['loss'], history.history['val_loss'], [train_acc], [val_acc]],\n",
        "                                               index=['train_loss','val_loss','train_acc','val_acc']).T)\n",
        "    df_history = df_history.reset_index(drop=\"Ture\")\n",
        "\n",
        "\n",
        "    # Elapsed time\n",
        "    elapsed_time = time.time() - start\n",
        "    print(\"Elapsed time:\", time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
        "\n",
        "    if i%10==0 and i>1:\n",
        "      # Create and save plot\n",
        "      save_plot(category, fold_id=k)\n",
        "      # Save a list of accuracy\n",
        "      df_history.to_csv(\"drive/My Drive/PointCloudAccuracy_10CV/Lun_\" + category + \"/df_log_\"+ str(k) + \".csv\")\n",
        "  \n",
        " \n",
        "  #   model.save_weights(\"drive/My Drive/Weights/style_model_weights.h5\")\n",
        "  #     plot_3d(i)\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================== Fold: 1 /10 ========================\n",
            "Generating training data 1 /3...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generating training data 2 /3...\n",
            "Generating training data 3 /3...\n",
            "Generating training data 1 /3...\n",
            "Generating training data 2 /3...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:69: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generating training data 3 /3...\n",
            "Compiling model...\n",
            "\n",
            " Total epoch: 1 / 500\n",
            "80/80 [==============================] - 10s 127ms/step\n",
            "Evaluation accuracy:  0.6\n",
            "627/627 [==============================] - 15s 24ms/step\n",
            "Evaluation accuracy:  0.5677830940988836\n",
            "Train on 627 samples, validate on 80 samples\n",
            "Epoch 1/1\n",
            "627/627 [==============================] - 63s 101ms/step - loss: 269.4898 - val_loss: 348.8543\n",
            "Elapsed time: 00:01:35\n",
            "\n",
            " Total epoch: 2 / 500\n",
            "80/80 [==============================] - 2s 23ms/step\n",
            "Evaluation accuracy:  0.55\n",
            "627/627 [==============================] - 15s 24ms/step\n",
            "Evaluation accuracy:  0.5422647527910686\n",
            "Train on 627 samples, validate on 80 samples\n",
            "Epoch 1/1\n",
            "627/627 [==============================] - 47s 75ms/step - loss: 48.5668 - val_loss: 101.2299\n",
            "Elapsed time: 00:02:40\n",
            "\n",
            " Total epoch: 3 / 500\n",
            "80/80 [==============================] - 2s 23ms/step\n",
            "Evaluation accuracy:  0.5625\n",
            "627/627 [==============================] - 15s 24ms/step\n",
            "Evaluation accuracy:  0.5470494417862839\n",
            "Train on 627 samples, validate on 80 samples\n",
            "Epoch 1/1\n",
            "627/627 [==============================] - 47s 75ms/step - loss: 23.8481 - val_loss: 99.0806\n",
            "Elapsed time: 00:03:46\n",
            "\n",
            " Total epoch: 4 / 500\n",
            "80/80 [==============================] - 2s 23ms/step\n",
            "Evaluation accuracy:  0.5375\n",
            "627/627 [==============================] - 15s 24ms/step\n",
            "Evaluation accuracy:  0.5151515151515151\n",
            "Train on 627 samples, validate on 80 samples\n",
            "Epoch 1/1\n",
            "627/627 [==============================] - 47s 75ms/step - loss: 10.8308 - val_loss: 70.9781\n",
            "Elapsed time: 00:04:51\n",
            "\n",
            " Total epoch: 5 / 500\n",
            "80/80 [==============================] - 2s 23ms/step\n",
            "Evaluation accuracy:  0.6125\n",
            "627/627 [==============================] - 15s 24ms/step\n",
            "Evaluation accuracy:  0.5215311004784688\n",
            "Train on 627 samples, validate on 80 samples\n",
            "Epoch 1/1\n",
            "192/627 [========>.....................] - ETA: 31s - loss: 14.2967"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-541cc24e0df1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_triplet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAnchor_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPositive_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNegative_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_dummy1\u001b[0m\u001b[0;34m,\u001b[0m                           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAnchor_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPositive_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNegative_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_dummy2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JybpD0yW8jzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_pickle(\"drive/My Drive/10CV_df/Lun_building/df_train_1.csv\").reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oQPmrgw8zsW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1ad25f08-899a-4bb7-fdf3-69e56e1a24ee"
      },
      "source": [
        "df_train.loc[:,\"query\"][0]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'148'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoUKsbeu8nUT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "6903c262-0bbb-49bb-edb4-9aa8e6407318"
      },
      "source": [
        "df_train"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>pos</th>\n",
              "      <th>neg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>148</td>\n",
              "      <td>157</td>\n",
              "      <td>161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100</td>\n",
              "      <td>95</td>\n",
              "      <td>207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>159</td>\n",
              "      <td>58</td>\n",
              "      <td>167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>55</td>\n",
              "      <td>187</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>97</td>\n",
              "      <td>44</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>622</th>\n",
              "      <td>194</td>\n",
              "      <td>111</td>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>623</th>\n",
              "      <td>58</td>\n",
              "      <td>26</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>624</th>\n",
              "      <td>238</td>\n",
              "      <td>216</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>625</th>\n",
              "      <td>187</td>\n",
              "      <td>99</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>626</th>\n",
              "      <td>104</td>\n",
              "      <td>127</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>627 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    query  pos  neg\n",
              "0     148  157  161\n",
              "1     100   95  207\n",
              "2     159   58  167\n",
              "3      55  187   44\n",
              "4      97   44  189\n",
              "..    ...  ...  ...\n",
              "622   194  111   89\n",
              "623    58   26  105\n",
              "624   238  216   32\n",
              "625   187   99   34\n",
              "626   104  127   68\n",
              "\n",
              "[627 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWM157g4VGFd",
        "colab_type": "code",
        "outputId": "c2e248e0-677e-4566-9948-7315ec0f6264",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "id = 0\n",
        "show_pc(Anchor_train[id,:,:])\n",
        "\n",
        "# train_points_rotate = rotate_point_cloud(Anchor_train[id,:,:])\n",
        "# train_points_jitter = jitter_point_cloud(train_points_rotate)\n",
        "# show_pc(train_points_rotate)\n",
        "# show_pc(train_points_jitter)\n",
        "\n",
        "# show_pc(input_data_a_trai)\n",
        "# show_pc(input_data_b_train[id,:,:])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nedryEoD5gAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCJikEgmqBC0",
        "colab_type": "code",
        "outputId": "b1d4a843-e1c5-4678-ee4d-3cbc5671c353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "df_history[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-1e8aa530aa14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'History' object does not support indexing"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEKSBBGRw0Zl",
        "colab_type": "code",
        "outputId": "eafd8718-c7c9-423b-91b3-5a1df061cd0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "evaluate_triplet(\"train\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "702/702 [==============================] - 20s 28ms/step\n",
            "Evaluation accuracy:  0.5555555555555556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07neOtkC5c5J",
        "colab_type": "code",
        "outputId": "895102f0-6f0c-4570-fc60-a5fee74f9e50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "from scipy.spatial import distance\n",
        "\n",
        "# Evaluate on test data\n",
        "X_train = [input_data_anchor_train,input_data_a_train, input_data_b_train]\n",
        "y_pred = model.predict(x=X_train,verbose=1)\n",
        "\n",
        "total_length = 1500\n",
        "alpha=50\n",
        "    \n",
        "anchor = y_pred[:,0:int(total_length*1/3)]\n",
        "positive = y_pred[:,int(total_length*1/3):int(total_length*2/3)]\n",
        "negative = y_pred[:,int(total_length*2/3):int(total_length*3/3)]\n",
        "\n",
        "pos_dist = distance.euclidean(anchor[0], positive[0])\n",
        "neg_dist = distance.euclidean(anchor[0], negative[0])\n",
        "\n",
        "# compute loss\n",
        "basic_loss = pos_dist - neg_dist + alpha\n",
        "loss = max(basic_loss,0.0)\n",
        "\n",
        "print(\"pos_dist: \", pos_dist)\n",
        "print(\"neg_dist: \", neg_dist)\n",
        "print(\"Loss:\", loss)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "201/201 [==============================] - 5s 24ms/step\n",
            "pos_dist:  37.07339096069336\n",
            "neg_dist:  35.5369758605957\n",
            "Loss: 51.536415100097656\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IlKwSkzqDJ5",
        "colab_type": "code",
        "outputId": "74529caf-f2eb-4274-f701-9d0eebfd3297",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "# Evaluate on test data\n",
        "y_true = np.zeros((X_test[0].shape[0],1))\n",
        "pred = model.predict(x=X_test,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-03bf46e12d02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaVe4pIQpOku",
        "colab_type": "code",
        "outputId": "a789aaa1-72f5-4514-fb78-6f663cde99d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Evaluate on training data\n",
        "y_true = np.zeros((X_train[0].shape[0],1))\n",
        "pred = model.predict(x=X_train,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "201/201 [==============================] - 5s 24ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsC-03L1qP2o",
        "colab_type": "code",
        "outputId": "db17b797-e90a-436a-9ae5-bee6c07f58e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Evaluate\n",
        "total_lenght = pred.shape[1]\n",
        "pred_anchor = pred[:,0:int(total_lenght*1/3)]\n",
        "pred_a = pred[:,int(total_lenght*1/3):int(total_lenght*2/3)]\n",
        "pred_b = pred[:,int(total_lenght*2/3):int(total_lenght*3/3)]\n",
        "pred_a.shape\n",
        "\n",
        "y_pred = []\n",
        "for i in range(pred.shape[0]):\n",
        "  dist_pos = distance.euclidean(pred_anchor[i], pred_a[i])\n",
        "  dist_neg = distance.euclidean(pred_anchor[i], pred_b[i])\n",
        "  print(\"Triplet\", i, \":\")\n",
        "  print(\"dist_pos\", dist_pos)\n",
        "  print(\"dist_neg\", dist_neg)\n",
        "  print(\"---------------------------------\")\n",
        "  if dist_pos < dist_neg:\n",
        "    y_pred.append(0)\n",
        "  else:\n",
        "    y_pred.append(1)   \n",
        "    \n",
        "\n",
        "print(accuracy_score(y_true, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Triplet 0 :\n",
            "dist_pos 4.61159086227417\n",
            "dist_neg 4.509746551513672\n",
            "---------------------------------\n",
            "Triplet 1 :\n",
            "dist_pos 11.08251953125\n",
            "dist_neg 12.058765411376953\n",
            "---------------------------------\n",
            "Triplet 2 :\n",
            "dist_pos 11.08251953125\n",
            "dist_neg 11.017613410949707\n",
            "---------------------------------\n",
            "Triplet 3 :\n",
            "dist_pos 4.61159086227417\n",
            "dist_neg 4.725347518920898\n",
            "---------------------------------\n",
            "Triplet 4 :\n",
            "dist_pos 10.023204803466797\n",
            "dist_neg 10.463550567626953\n",
            "---------------------------------\n",
            "Triplet 5 :\n",
            "dist_pos 9.939489364624023\n",
            "dist_neg 12.058765411376953\n",
            "---------------------------------\n",
            "Triplet 6 :\n",
            "dist_pos 10.023204803466797\n",
            "dist_neg 9.752119064331055\n",
            "---------------------------------\n",
            "Triplet 7 :\n",
            "dist_pos 5.878297328948975\n",
            "dist_neg 6.098970413208008\n",
            "---------------------------------\n",
            "Triplet 8 :\n",
            "dist_pos 10.085077285766602\n",
            "dist_neg 4.949539661407471\n",
            "---------------------------------\n",
            "Triplet 9 :\n",
            "dist_pos 10.615157127380371\n",
            "dist_neg 8.90152359008789\n",
            "---------------------------------\n",
            "Triplet 10 :\n",
            "dist_pos 6.728908061981201\n",
            "dist_neg 6.098970413208008\n",
            "---------------------------------\n",
            "Triplet 11 :\n",
            "dist_pos 4.561391830444336\n",
            "dist_neg 4.3818888664245605\n",
            "---------------------------------\n",
            "Triplet 12 :\n",
            "dist_pos 10.652087211608887\n",
            "dist_neg 11.017613410949707\n",
            "---------------------------------\n",
            "Triplet 13 :\n",
            "dist_pos 10.023204803466797\n",
            "dist_neg 5.390899658203125\n",
            "---------------------------------\n",
            "Triplet 14 :\n",
            "dist_pos 9.368084907531738\n",
            "dist_neg 9.474443435668945\n",
            "---------------------------------\n",
            "Triplet 15 :\n",
            "dist_pos 9.524996757507324\n",
            "dist_neg 8.506394386291504\n",
            "---------------------------------\n",
            "Triplet 16 :\n",
            "dist_pos 8.657129287719727\n",
            "dist_neg 5.362087726593018\n",
            "---------------------------------\n",
            "Triplet 17 :\n",
            "dist_pos 6.100005626678467\n",
            "dist_neg 9.63115406036377\n",
            "---------------------------------\n",
            "Triplet 18 :\n",
            "dist_pos 4.561391830444336\n",
            "dist_neg 4.369719505310059\n",
            "---------------------------------\n",
            "Triplet 19 :\n",
            "dist_pos 4.97120475769043\n",
            "dist_neg 5.362087726593018\n",
            "---------------------------------\n",
            "Triplet 20 :\n",
            "dist_pos 4.791695594787598\n",
            "dist_neg 4.808250427246094\n",
            "---------------------------------\n",
            "Triplet 21 :\n",
            "dist_pos 5.359409332275391\n",
            "dist_neg 6.098970413208008\n",
            "---------------------------------\n",
            "Triplet 22 :\n",
            "dist_pos 6.100005626678467\n",
            "dist_neg 9.582945823669434\n",
            "---------------------------------\n",
            "Triplet 23 :\n",
            "dist_pos 3.1129202842712402\n",
            "dist_neg 7.106855392456055\n",
            "---------------------------------\n",
            "Triplet 24 :\n",
            "dist_pos 7.8303046226501465\n",
            "dist_neg 10.567907333374023\n",
            "---------------------------------\n",
            "Triplet 25 :\n",
            "dist_pos 8.720673561096191\n",
            "dist_neg 5.175645351409912\n",
            "---------------------------------\n",
            "Triplet 26 :\n",
            "dist_pos 5.841269016265869\n",
            "dist_neg 4.7462592124938965\n",
            "---------------------------------\n",
            "Triplet 27 :\n",
            "dist_pos 4.791695594787598\n",
            "dist_neg 5.178389549255371\n",
            "---------------------------------\n",
            "Triplet 28 :\n",
            "dist_pos 4.697126388549805\n",
            "dist_neg 4.949539661407471\n",
            "---------------------------------\n",
            "Triplet 29 :\n",
            "dist_pos 8.801480293273926\n",
            "dist_neg 4.7462592124938965\n",
            "---------------------------------\n",
            "Triplet 30 :\n",
            "dist_pos 8.76913070678711\n",
            "dist_neg 10.049700736999512\n",
            "---------------------------------\n",
            "Triplet 31 :\n",
            "dist_pos 5.301929950714111\n",
            "dist_neg 9.110692977905273\n",
            "---------------------------------\n",
            "Triplet 32 :\n",
            "dist_pos 5.841269016265869\n",
            "dist_neg 6.6540703773498535\n",
            "---------------------------------\n",
            "Triplet 33 :\n",
            "dist_pos 10.615157127380371\n",
            "dist_neg 8.45911979675293\n",
            "---------------------------------\n",
            "Triplet 34 :\n",
            "dist_pos 9.939489364624023\n",
            "dist_neg 9.824679374694824\n",
            "---------------------------------\n",
            "Triplet 35 :\n",
            "dist_pos 8.801480293273926\n",
            "dist_neg 6.6540703773498535\n",
            "---------------------------------\n",
            "Triplet 36 :\n",
            "dist_pos 8.377171516418457\n",
            "dist_neg 4.97120475769043\n",
            "---------------------------------\n",
            "Triplet 37 :\n",
            "dist_pos 6.722275733947754\n",
            "dist_neg 5.359409332275391\n",
            "---------------------------------\n",
            "Triplet 38 :\n",
            "dist_pos 10.615157127380371\n",
            "dist_neg 9.259942054748535\n",
            "---------------------------------\n",
            "Triplet 39 :\n",
            "dist_pos 5.841269016265869\n",
            "dist_neg 10.085077285766602\n",
            "---------------------------------\n",
            "Triplet 40 :\n",
            "dist_pos 8.76913070678711\n",
            "dist_neg 8.45911979675293\n",
            "---------------------------------\n",
            "Triplet 41 :\n",
            "dist_pos 9.259942054748535\n",
            "dist_neg 8.446183204650879\n",
            "---------------------------------\n",
            "Triplet 42 :\n",
            "dist_pos 5.381901264190674\n",
            "dist_neg 9.474443435668945\n",
            "---------------------------------\n",
            "Triplet 43 :\n",
            "dist_pos 8.76913070678711\n",
            "dist_neg 9.259942054748535\n",
            "---------------------------------\n",
            "Triplet 44 :\n",
            "dist_pos 7.861288070678711\n",
            "dist_neg 4.509746551513672\n",
            "---------------------------------\n",
            "Triplet 45 :\n",
            "dist_pos 8.76913070678711\n",
            "dist_neg 8.90152359008789\n",
            "---------------------------------\n",
            "Triplet 46 :\n",
            "dist_pos 4.7572855949401855\n",
            "dist_neg 7.079197883605957\n",
            "---------------------------------\n",
            "Triplet 47 :\n",
            "dist_pos 4.6214094161987305\n",
            "dist_neg 4.854172229766846\n",
            "---------------------------------\n",
            "Triplet 48 :\n",
            "dist_pos 5.762890338897705\n",
            "dist_neg 4.509746551513672\n",
            "---------------------------------\n",
            "Triplet 49 :\n",
            "dist_pos 8.459742546081543\n",
            "dist_neg 10.33910846710205\n",
            "---------------------------------\n",
            "Triplet 50 :\n",
            "dist_pos 5.705846786499023\n",
            "dist_neg 9.474443435668945\n",
            "---------------------------------\n",
            "Triplet 51 :\n",
            "dist_pos 6.100005626678467\n",
            "dist_neg 10.463550567626953\n",
            "---------------------------------\n",
            "Triplet 52 :\n",
            "dist_pos 5.705846786499023\n",
            "dist_neg 4.990041732788086\n",
            "---------------------------------\n",
            "Triplet 53 :\n",
            "dist_pos 8.377171516418457\n",
            "dist_neg 8.657129287719727\n",
            "---------------------------------\n",
            "Triplet 54 :\n",
            "dist_pos 10.429597854614258\n",
            "dist_neg 12.291290283203125\n",
            "---------------------------------\n",
            "Triplet 55 :\n",
            "dist_pos 7.8303046226501465\n",
            "dist_neg 11.243925094604492\n",
            "---------------------------------\n",
            "Triplet 56 :\n",
            "dist_pos 6.100005626678467\n",
            "dist_neg 8.506394386291504\n",
            "---------------------------------\n",
            "Triplet 57 :\n",
            "dist_pos 2.754516363143921\n",
            "dist_neg 7.079197883605957\n",
            "---------------------------------\n",
            "Triplet 58 :\n",
            "dist_pos 8.45911979675293\n",
            "dist_neg 10.049700736999512\n",
            "---------------------------------\n",
            "Triplet 59 :\n",
            "dist_pos 7.8303046226501465\n",
            "dist_neg 9.507120132446289\n",
            "---------------------------------\n",
            "Triplet 60 :\n",
            "dist_pos 6.722275733947754\n",
            "dist_neg 6.098970413208008\n",
            "---------------------------------\n",
            "Triplet 61 :\n",
            "dist_pos 6.100005626678467\n",
            "dist_neg 9.5352144241333\n",
            "---------------------------------\n",
            "Triplet 62 :\n",
            "dist_pos 6.6540703773498535\n",
            "dist_neg 4.949539661407471\n",
            "---------------------------------\n",
            "Triplet 63 :\n",
            "dist_pos 4.791695594787598\n",
            "dist_neg 5.091285228729248\n",
            "---------------------------------\n",
            "Triplet 64 :\n",
            "dist_pos 8.657129287719727\n",
            "dist_neg 11.843687057495117\n",
            "---------------------------------\n",
            "Triplet 65 :\n",
            "dist_pos 11.585813522338867\n",
            "dist_neg 12.51418685913086\n",
            "---------------------------------\n",
            "Triplet 66 :\n",
            "dist_pos 6.100005626678467\n",
            "dist_neg 9.828105926513672\n",
            "---------------------------------\n",
            "Triplet 67 :\n",
            "dist_pos 4.561391830444336\n",
            "dist_neg 7.106855392456055\n",
            "---------------------------------\n",
            "Triplet 68 :\n",
            "dist_pos 4.791695594787598\n",
            "dist_neg 4.144290924072266\n",
            "---------------------------------\n",
            "Triplet 69 :\n",
            "dist_pos 3.7095963954925537\n",
            "dist_neg 7.079197883605957\n",
            "---------------------------------\n",
            "Triplet 70 :\n",
            "dist_pos 8.377171516418457\n",
            "dist_neg 5.362087726593018\n",
            "---------------------------------\n",
            "Triplet 71 :\n",
            "dist_pos 6.722275733947754\n",
            "dist_neg 5.878297328948975\n",
            "---------------------------------\n",
            "Triplet 72 :\n",
            "dist_pos 6.42333984375\n",
            "dist_neg 4.854172229766846\n",
            "---------------------------------\n",
            "Triplet 73 :\n",
            "dist_pos 4.97120475769043\n",
            "dist_neg 11.843687057495117\n",
            "---------------------------------\n",
            "Triplet 74 :\n",
            "dist_pos 8.45911979675293\n",
            "dist_neg 8.446183204650879\n",
            "---------------------------------\n",
            "Triplet 75 :\n",
            "dist_pos 3.6434481143951416\n",
            "dist_neg 6.098970413208008\n",
            "---------------------------------\n",
            "Triplet 76 :\n",
            "dist_pos 3.83682918548584\n",
            "dist_neg 3.7095963954925537\n",
            "---------------------------------\n",
            "Triplet 77 :\n",
            "dist_pos 3.1129202842712402\n",
            "dist_neg 4.369719505310059\n",
            "---------------------------------\n",
            "Triplet 78 :\n",
            "dist_pos 3.83682918548584\n",
            "dist_neg 7.079197883605957\n",
            "---------------------------------\n",
            "Triplet 79 :\n",
            "dist_pos 10.615157127380371\n",
            "dist_neg 10.049700736999512\n",
            "---------------------------------\n",
            "Triplet 80 :\n",
            "dist_pos 4.808250427246094\n",
            "dist_neg 4.144290924072266\n",
            "---------------------------------\n",
            "Triplet 81 :\n",
            "dist_pos 5.935725212097168\n",
            "dist_neg 7.079197883605957\n",
            "---------------------------------\n",
            "Triplet 82 :\n",
            "dist_pos 5.841269016265869\n",
            "dist_neg 7.569982051849365\n",
            "---------------------------------\n",
            "Triplet 83 :\n",
            "dist_pos 6.722275733947754\n",
            "dist_neg 3.6434481143951416\n",
            "---------------------------------\n",
            "Triplet 84 :\n",
            "dist_pos 9.524996757507324\n",
            "dist_neg 5.467439651489258\n",
            "---------------------------------\n",
            "Triplet 85 :\n",
            "dist_pos 8.370471954345703\n",
            "dist_neg 10.33910846710205\n",
            "---------------------------------\n",
            "Triplet 86 :\n",
            "dist_pos 8.801480293273926\n",
            "dist_neg 10.085077285766602\n",
            "---------------------------------\n",
            "Triplet 87 :\n",
            "dist_pos 10.481778144836426\n",
            "dist_neg 11.302891731262207\n",
            "---------------------------------\n",
            "Triplet 88 :\n",
            "dist_pos 8.801480293273926\n",
            "dist_neg 7.569982051849365\n",
            "---------------------------------\n",
            "Triplet 89 :\n",
            "dist_pos 9.259942054748535\n",
            "dist_neg 10.33910846710205\n",
            "---------------------------------\n",
            "Triplet 90 :\n",
            "dist_pos 5.091285228729248\n",
            "dist_neg 4.144290924072266\n",
            "---------------------------------\n",
            "Triplet 91 :\n",
            "dist_pos 6.100005626678467\n",
            "dist_neg 9.752119064331055\n",
            "---------------------------------\n",
            "Triplet 92 :\n",
            "dist_pos 5.381901264190674\n",
            "dist_neg 4.990041732788086\n",
            "---------------------------------\n",
            "Triplet 93 :\n",
            "dist_pos 8.377171516418457\n",
            "dist_neg 3.902076482772827\n",
            "---------------------------------\n",
            "Triplet 94 :\n",
            "dist_pos 10.023204803466797\n",
            "dist_neg 9.5352144241333\n",
            "---------------------------------\n",
            "Triplet 95 :\n",
            "dist_pos 10.085077285766602\n",
            "dist_neg 9.110692977905273\n",
            "---------------------------------\n",
            "Triplet 96 :\n",
            "dist_pos 8.377171516418457\n",
            "dist_neg 11.843687057495117\n",
            "---------------------------------\n",
            "Triplet 97 :\n",
            "dist_pos 7.8303046226501465\n",
            "dist_neg 10.12889575958252\n",
            "---------------------------------\n",
            "Triplet 98 :\n",
            "dist_pos 4.791695594787598\n",
            "dist_neg 5.017581939697266\n",
            "---------------------------------\n",
            "Triplet 99 :\n",
            "dist_pos 8.251555442810059\n",
            "dist_neg 4.854172229766846\n",
            "---------------------------------\n",
            "Triplet 100 :\n",
            "dist_pos 5.301929950714111\n",
            "dist_neg 4.949539661407471\n",
            "---------------------------------\n",
            "Triplet 101 :\n",
            "dist_pos 8.45911979675293\n",
            "dist_neg 10.33910846710205\n",
            "---------------------------------\n",
            "Triplet 102 :\n",
            "dist_pos 5.390899658203125\n",
            "dist_neg 9.752119064331055\n",
            "---------------------------------\n",
            "Triplet 103 :\n",
            "dist_pos 3.7095963954925537\n",
            "dist_neg 4.369719505310059\n",
            "---------------------------------\n",
            "Triplet 104 :\n",
            "dist_pos 5.705846786499023\n",
            "dist_neg 5.059548377990723\n",
            "---------------------------------\n",
            "Triplet 105 :\n",
            "dist_pos 11.585813522338867\n",
            "dist_neg 12.520672798156738\n",
            "---------------------------------\n",
            "Triplet 106 :\n",
            "dist_pos 7.8303046226501465\n",
            "dist_neg 7.766021728515625\n",
            "---------------------------------\n",
            "Triplet 107 :\n",
            "dist_pos 9.368084907531738\n",
            "dist_neg 4.990041732788086\n",
            "---------------------------------\n",
            "Triplet 108 :\n",
            "dist_pos 4.725347518920898\n",
            "dist_neg 4.509746551513672\n",
            "---------------------------------\n",
            "Triplet 109 :\n",
            "dist_pos 10.652087211608887\n",
            "dist_neg 12.058765411376953\n",
            "---------------------------------\n",
            "Triplet 110 :\n",
            "dist_pos 9.939489364624023\n",
            "dist_neg 11.017613410949707\n",
            "---------------------------------\n",
            "Triplet 111 :\n",
            "dist_pos 8.720673561096191\n",
            "dist_neg 9.031473159790039\n",
            "---------------------------------\n",
            "Triplet 112 :\n",
            "dist_pos 6.098562717437744\n",
            "dist_neg 4.509746551513672\n",
            "---------------------------------\n",
            "0.5575221238938053\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj4PTFqeC0Wt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.set_printoptions(precision=2)\n",
        "np.set_printoptions(suppress=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJcxmFFAWI81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scaling\n",
        "from sklearn import preprocessing\n",
        "mm = preprocessing.MinMaxScaler()\n",
        "for i in range(len(test_points)):\n",
        "    test_points[i] = mm.fit_transform(test_points[i])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}